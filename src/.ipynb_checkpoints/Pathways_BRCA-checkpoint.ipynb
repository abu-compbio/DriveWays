{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from gseapy.parser import gsea_gmt_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "pathways = [ 'c2.cp.kegg.v6.2.symbols.gmt','c2.cp.kegg.v5.0.symbols.txt', 'c2.cp.reactome.v5.0.symbols.txt', 'c2.cp.biocarta.v5.0.symbols.txt']\n",
    "names = ['Kegg6.2', 'Kegg5.0','Reactome5.0', 'Biocarta5.0']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sn(T, N):\n",
    "    '''\n",
    "    T: n x m matrix, T_ij= |R_i inters P_j|\n",
    "    N: list of n entries, n_i= |R_i|\n",
    "    '''\n",
    "    nem = np.sum(np.max(T, axis=1))\n",
    "    den = sum(N)\n",
    "    return nem/den\n",
    "\n",
    "def PPV(T):\n",
    "    return np.sum(np.max(T, axis=0))/np.sum(T)\n",
    "\n",
    "\n",
    "def gmt_parser(file):\n",
    "    dict_ = gsea_gmt_parser(file)\n",
    "    modules = []\n",
    "    c,s = 0,0\n",
    "\n",
    "    for k in dict_.keys():\n",
    "        # if not len(dict_[k]) < 3 and not len(dict_[k]) > 300:\n",
    "        modules.append(dict_[k])\n",
    "    #     else:\n",
    "    #         if len(dict_[k]) < 3: c += 1\n",
    "    #         else: s += 1\n",
    "    # print('There are {} pathways with less than 3 genes and {} more than 300 genes'.format(c,s))\n",
    "    return modules\n",
    "\n",
    "def txt_parser(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "    c,s = 0,0\n",
    "    modules = []\n",
    "    for l in lines[1:]:\n",
    "        m = l.strip().split('\\t')[1].split(',')\n",
    "        # if not len(m) < 3 and not len(m) > 300:\n",
    "        modules.append(m)\n",
    "    #     else:\n",
    "    #         if len(m) < 3: c += 1\n",
    "    #         else: s += 1\n",
    "    # print('There are {} pathways with less than 3 genes and {} more than 300 genes'.format(c,s))\n",
    "    return modules\n",
    "def txt_parser2(file):\n",
    "\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        modules = [l.strip().split() for l in lines]\n",
    "\n",
    "    return modules\n",
    "\n",
    "\n",
    "def predict_modules(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    return [l.strip().split() for l in lines]\n",
    "def cosmic_genes():\n",
    "\n",
    "    fhinput = open('../data/Census_allFri Apr 26 12_49_57 2019.csv')\n",
    "    cosmic_genes = []\n",
    "    line = fhinput.readline()\n",
    "    for line in fhinput:\n",
    "        cosmic_genes.append(line.split(',')[0])\n",
    "    return cosmic_genes\n",
    "\n",
    "def NCG_BRCA_genes():\n",
    "\n",
    "    fhinput = open('../data/NCG_Ref_data_intersection_COSMIC_BRCA.txt')\n",
    "    genes = [s.strip() for s in fhinput.readlines()]\n",
    "    return genes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosmic = NCG_BRCA_genes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kegg6.2 There are 64/186 pathways, unique/total 80/719\n",
      "Kegg5.0 There are 64/186 pathways, unique/total 80/719\n",
      "Reactome5.0 There are 142/674 pathways, unique/total 78/942\n",
      "Biocarta5.0 There are 85/217 pathways, unique/total 57/418\n"
     ]
    }
   ],
   "source": [
    "new_pathways = []\n",
    "all_org_genes = []\n",
    "for name,p in zip(names,pathways):\n",
    "    tmp_pathways = []\n",
    "    genes = []\n",
    "    org_genes = []\n",
    "    \n",
    "    if p.split('.')[-1] == 'gmt':\n",
    "#         print('gmt parser')\n",
    "        # print(data_path+p)\n",
    "        ref_modules = gmt_parser(data_path+p)\n",
    "\n",
    "    elif p.split('.')[-1] == 'txt':\n",
    "#         print('txt parser')\n",
    "        ref_modules = txt_parser(data_path+p)\n",
    "\n",
    "    for R in ref_modules:\n",
    "        org_genes.extend(R)\n",
    "        inters = set(R).intersection(set(cosmic))\n",
    "        if len(inters) >2:\n",
    "            genes.extend(inters)\n",
    "            tmp_pathways.append(inters)\n",
    "    \n",
    "    print('{} There are {}/{} pathways, unique/total {}/{}'.format(name,len(tmp_pathways), len(ref_modules), len(set(genes)),len(genes)))\n",
    "#     with open('../data/{}_new.txt'.format(name), 'w') as f:\n",
    "#         f.write('\\n'.join([' '.join(m) for m in tmp_pathways]))\n",
    "    new_pathways.append(tmp_pathways)\n",
    "    all_org_genes.append(org_genes)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.5       , 0.33333333, 0.25      , 0.2       ,\n",
       "       0.16666667, 0.14285714, 0.125     , 0.11111111, 0.1       ])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [float('inf')]+list(np.linspace(0.1,1,10))\n",
    "1/np.linspace(1,10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kegg_all_genes_for_gettingSysnonyms.txt', 'w') as f:\n",
    "    f.write('\\n'.join(all_org_genes[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reactom_all_genes_for_gettingSysnonyms.txt', 'w') as f:\n",
    "    f.write('\\n'.join(all_org_genes[2]))\n",
    "\n",
    "with open('biocarta_all_genes_for_gettingSysnonyms.txt', 'w') as f:\n",
    "    f.write('\\n'.join(all_org_genes[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kegg = pd.read_csv('../data/kegg_gene_to_synonym.tab',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kegg = df_kegg[['yourlist:M201905026746803381A1F0E0DB47453E0216320D0EBDEE9','Gene names']]\n",
    "df_kegg.columns = ['Name','Synon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kegg = df_kegg.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kegg['Synon'] = df_kegg.Synon.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_indx = [i for i,s in enumerate(df_kegg['Synon'].values) if len(s)>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kegg = df_kegg.iloc[keep_indx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Synon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACSS2</td>\n",
       "      <td>[ACSS2, hCG_38506]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACSS2</td>\n",
       "      <td>[ACSS2, ACAS2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GCK</td>\n",
       "      <td>[GCK, hCG_1745191, tcag7.801]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PGK2</td>\n",
       "      <td>[PGK2, PGKB]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PGK1</td>\n",
       "      <td>[PGK1, PGKA, MIG10, OK/SW-cl.110]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name                              Synon\n",
       "1  ACSS2                 [ACSS2, hCG_38506]\n",
       "2  ACSS2                     [ACSS2, ACAS2]\n",
       "4    GCK      [GCK, hCG_1745191, tcag7.801]\n",
       "5   PGK2                       [PGK2, PGKB]\n",
       "6   PGK1  [PGK1, PGKA, MIG10, OK/SW-cl.110]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_kegg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACSS2', 'hCG_38506']\n",
      "['ACSS2', 'ACAS2']\n"
     ]
    }
   ],
   "source": [
    "for r in df_kegg[df_kegg.Name == 'ACSS2']['Synon']:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg = gmt_parser(data_path+pathways[0])\n",
    "modules = []\n",
    "for m in kegg:\n",
    "    tmp = []\n",
    "    for g in m:\n",
    "        tmp.append(g)\n",
    "        for r in df_kegg[df_kegg.Name == g]['Synon']:\n",
    "            tmp.extend(r)\n",
    "    modules.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cosmic genes in Kegg  88\n"
     ]
    }
   ],
   "source": [
    "cosmic = NCG_BRCA_genes()\n",
    "kegg = gmt_parser(data_path+pathways[0])\n",
    "# cosmic_all = []\n",
    "# for m in cosmic:\n",
    "#     cosmic_all.extend(m)\n",
    "kegg_all = []\n",
    "for m in kegg:\n",
    "    kegg_all.extend(m)\n",
    "print('Number of Cosmic genes in Original Kegg ', len(set(cosmic).intersection(set(kegg_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Cosmic genes in Kegg  91\n"
     ]
    }
   ],
   "source": [
    "kegg_all = []\n",
    "for m in modules:\n",
    "    kegg_all.extend(m)\n",
    "print('Number of Cosmic genes in Kegg ', len(set(cosmic).intersection(set(kegg_all))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "unique = set()\n",
    "with open('../data/{}_BRCA.txt'.format('kegg6.2'), 'w') as f:\n",
    "    moduels_ = []\n",
    "    for m in modules:\n",
    "        inters =set(cosmic).intersection(set(m))\n",
    "        if len(inters) > 2:\n",
    "            total_count += len(inters)\n",
    "            unique  = unique.union(set(inters))\n",
    "            moduels_.append(inters)\n",
    "    f.write('\\n'.join([' '.join(m) for m in moduels_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 81, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count, len(unique), len(moduels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fd = []\n",
    "for m in moduels_:\n",
    "    fd.extend(m)\n",
    "len(set(cosmic).intersection(set(fd)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactom = pd.read_csv('../data/reactom_gene_to_synonym.tab',sep='\\t')\n",
    "# df_reactom.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reactom = df_reactom[['yourlist:M201905286746803381A1F0E0DB47453E0216320D183D73W','Gene names']]\n",
    "df_reactom.columns = ['Name','Synon']\n",
    "df_reactom = df_reactom.drop_duplicates().reset_index(drop=True)\n",
    "df_reactom['Synon'] = df_reactom.Synon.apply(lambda x: x.split())\n",
    "keep_indx = [i for i,s in enumerate(df_reactom['Synon'].values) if len(s)>1]\n",
    "df_reactom = df_reactom.iloc[keep_indx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactom = txt_parser(data_path+pathways[2])\n",
    "modules = []\n",
    "for m in reactom:\n",
    "    tmp = []\n",
    "    for g in m:\n",
    "        tmp.append(g)\n",
    "        for r in df_reactom[df_reactom.Name == g]['Synon']:\n",
    "            tmp.extend(r)\n",
    "    modules.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "unique = set()\n",
    "with open('../data/{}_BRCA.txt'.format('Reactom5.0'), 'w') as f:\n",
    "    moduels_ = []\n",
    "    for m in modules:\n",
    "        inters =set(cosmic).intersection(set(m))\n",
    "        if len(inters) > 2:\n",
    "            total_count += len(inters)\n",
    "            unique  = unique.union(set(inters))\n",
    "            moduels_.append(inters)\n",
    "    f.write('\\n'.join([' '.join(m) for m in moduels_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(957, 82, 144)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count, len(unique), len(moduels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biocarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biocarta = pd.read_csv('../data/biocarta_gene_to_synonym.tab',sep='\\t')\n",
    "# df_biocarta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_biocarta = df_biocarta[['yourlist:M201905286746803381A1F0E0DB47453E0216320D183D79W','Gene names']]\n",
    "df_biocarta.columns = ['Name','Synon']\n",
    "df_biocarta = df_biocarta.drop_duplicates().reset_index(drop=True)\n",
    "df_biocarta['Synon'] = df_biocarta.Synon.apply(lambda x: x.split())\n",
    "keep_indx = [i for i,s in enumerate(df_biocarta['Synon'].values) if len(s)>1]\n",
    "df_biocarta = df_biocarta.iloc[keep_indx,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "biocarta = txt_parser(data_path+pathways[3])\n",
    "modules = []\n",
    "for m in biocarta:\n",
    "    tmp = []\n",
    "    for g in m:\n",
    "        tmp.append(g)\n",
    "        for r in df_biocarta[df_biocarta.Name == g]['Synon']:\n",
    "            tmp.extend(r)\n",
    "    modules.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_count = 0\n",
    "unique = set()\n",
    "with open('../data/{}_BRCA.txt'.format('Biocarta5.0'), 'w') as f:\n",
    "    moduels_ = []\n",
    "    for m in modules:\n",
    "        inters =set(cosmic).intersection(set(m))\n",
    "        if len(inters) > 2:\n",
    "            total_count += len(inters)\n",
    "            unique  = unique.union(set(inters))\n",
    "            moduels_.append(inters)\n",
    "    f.write('\\n'.join([' '.join(m) for m in moduels_]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 57, 85)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count, len(unique), len(moduels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kegg6.2 has 102 modules and 1462 total genes, unique gene 277\n",
      "Kegg5.0 has 102 modules and 1462 total genes, unique gene 277\n",
      "Reactome5.0 has 303 modules and 2793 total genes, unique gene 295\n",
      "Biocarta5.0 has 141 modules and 1010 total genes, unique gene 165\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    ref_modules= txt_parser2(data_path+'{}_new.txt'.format(name))\n",
    "    all_genes = []\n",
    "    for m in ref_modules:\n",
    "        all_genes.extend(m)\n",
    "    print('{} has {} modules and {} total genes, unique gene {}'.format(name, len(ref_modules), len(all_genes), len(set(all_genes))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
