{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from gseapy.parser import gsea_gmt_parser\n",
    "from strategy.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_modules(file):\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "    modules = [l.strip().split() for l in lines]\n",
    "    modules_ = []\n",
    "    mapping = {}\n",
    "    index = 0\n",
    "    for i,l in enumerate(modules):\n",
    "        if len(l) >= 2000:\n",
    "            # np.random.shuffle(l)\n",
    "            # l = list(l)\n",
    "            mapping[index] = '{}_1'.format(i)\n",
    "            mapping[index+1] = '{}_2'.format(i)\n",
    "            index +=2\n",
    "            modules_.extend([l[:len(l)//2], l[len(l)//2:]])\n",
    "        else:\n",
    "            mapping[index] = '{}'.format(i)\n",
    "            index +=1\n",
    "            modules_.append(l)\n",
    "    return modules_, mapping\n",
    "\n",
    "def cosmic_genes():\n",
    "    fhinput = open('../data/Census_allTue_May_23_12-08-15_2017.tsv')\n",
    "    cosmic_genes = []\n",
    "    line = fhinput.readline()\n",
    "    for line in fhinput:\n",
    "        cosmic_genes.append(line.split()[0])\n",
    "    return cosmic_genes\n",
    "\n",
    "def NCG_BRCA_genes():\n",
    "\n",
    "    fhinput = open('../data/NCG_Ref_data_intersection_COSMIC_BRCA.txt')\n",
    "    genes = [s.strip() for s in fhinput.readlines()]\n",
    "    return genes\n",
    "\n",
    "def txt_parser2(file):\n",
    "\n",
    "    with open(file) as f:\n",
    "        lines = f.readlines()\n",
    "        modules = [l.strip().split() for l in lines]\n",
    "\n",
    "    return modules\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "conversion_df = pd.read_csv('/Users/mac/Downloads/Expander/organisms/human/varob.txt', \n",
    "                            sep='\\t', names=['index','symbol','ID']).drop('index', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_mapping = {'AIM1':'AURKB' ,\n",
    "    'BAI2':'ADGRB2',\n",
    "    'C9orf117':'CFAP157',\n",
    "    'FAM123A':'AMER2',\n",
    "    'KIAA0913':'ZSWIM8',\n",
    "    'KIAA0947': 'ICE1',\n",
    "    'KIAA1377': 'CEP126',\n",
    "    'KIAA1875':'WDR97',\n",
    "    'LPHN2':'ADGRL2',\n",
    "    'MLL':'KMT2A',\n",
    "    'MLL4':'KMT2D',\n",
    "    'MLLT4':'AFDN' ,\n",
    "    'ODZ2':'TENM2',\n",
    "    'PARK2':'PRKN',\n",
    "    'PCNX':'PCNX1',\n",
    "    'PRIC285':'HELZ2',\n",
    "    'RLTPR':'CARMIL2',\n",
    "    'SEPP1':'SELENOP',\n",
    "    'UFD1L':'UFD1',\n",
    "    'WHSC1L1':'NSD3',\n",
    "    'MML5':'KMT2E',\n",
    "    'WHSC1':'NSD2'\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kegg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_stats(file):\n",
    "    out_modules,_ = predict_modules(file)\n",
    "    predicted_genes = []\n",
    "    for p in out_modules:\n",
    "        predicted_genes.extend(p)\n",
    "    predicted_genes = set(predicted_genes)\n",
    "    data_path = '../data/'\n",
    "    kegg_pathways = txt_parser2(data_path+'kegg6.2_02_05_2019.txt')\n",
    "    reactom_pathways = txt_parser2(data_path+'reactom5.0_02_05_2019.txt')\n",
    "    biocarta_pathways = txt_parser2(data_path+'biocarta5.0_02_05_2019.txt')\n",
    "    \n",
    "    kegg_genes = []\n",
    "    reactom_genes = []\n",
    "    biocarta_genes = []\n",
    "    for p in kegg_pathways:\n",
    "        kegg_genes.extend(p)\n",
    "\n",
    "    for p in reactom_pathways:\n",
    "        reactom_genes.extend(p)\n",
    "\n",
    "    for p in biocarta_pathways:\n",
    "        biocarta_genes.extend(p)\n",
    "    \n",
    "    print(f'There are {len(out_modules)} modules ')\n",
    "    print(f'There are {len(predicted_genes)} unique genes ')\n",
    "    print(f'# of genes inters with Kegg {len(set(kegg_genes).intersection(predicted_genes))}')\n",
    "    print(f'# of genes inters with Reactom {len(set(reactom_genes).intersection(predicted_genes))}')\n",
    "    print(f'# of genes inters with Biocarta {len(set(biocarta_genes).intersection(predicted_genes))}')\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_stats_BRCA(file):\n",
    "    out_modules,_ = predict_modules(file)\n",
    "    predicted_genes = []\n",
    "    for p in out_modules:\n",
    "        predicted_genes.extend(p)\n",
    "    predicted_genes = set(predicted_genes)\n",
    "    BRCA_genes = NCG_BRCA_genes()\n",
    "    \n",
    "    data_path = '../data/'\n",
    "    kegg_pathways = txt_parser2(data_path+'kegg6.2_BRCA.txt')\n",
    "    reactom_pathways = txt_parser2(data_path+'reactom5.0_BRCA.txt')\n",
    "    biocarta_pathways = txt_parser2(data_path+'biocarta5.0_BRCA.txt')\n",
    "    \n",
    "    kegg_genes = []\n",
    "    reactom_genes = []\n",
    "    biocarta_genes = []\n",
    "    for p in kegg_pathways:\n",
    "        kegg_genes.extend(p)\n",
    "\n",
    "    for p in reactom_pathways:\n",
    "        reactom_genes.extend(p)\n",
    "\n",
    "    for p in biocarta_pathways:\n",
    "        biocarta_genes.extend(p)\n",
    "    \n",
    "    print(f'There are {len(out_modules)} modules ')\n",
    "    print(f'There are {len(predicted_genes)} unique genes ')\n",
    "    print(f'# of genes inters with Kegg {len(set(kegg_genes).intersection(predicted_genes))}')\n",
    "    print(f'# of genes inters with Reactom {len(set(reactom_genes).intersection(predicted_genes))}')\n",
    "    print(f'# of genes inters with Biocarta {len(set(biocarta_genes).intersection(predicted_genes))}')\n",
    "    \n",
    "    print(f'# of NCG_BRCA_genes inters with Kegg {len(set(kegg_genes).intersection(BRCA_genes))}')\n",
    "    print(f'# of NCG_BRCA_genes inters with Reactom {len(set(reactom_genes).intersection(BRCA_genes))}')\n",
    "    print(f'# of NCG_BRCA_genes inters with Biocarta {len(set(biocarta_genes).intersection(BRCA_genes))}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=4\n",
    "t=1.4\n",
    "#d=1; t=0.92 # these params give # of modules similar to kegg\n",
    "comp_folder = '../out/components/24_06_2019/'\n",
    "comp_file = 'd{}_t{}/cc_n1771_k3.txt'.format(d,t )\n",
    "pred_modules, mapping = predict_modules(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 507 modules \n",
      "There are 643 unique genes \n",
      "# of genes inters with Kegg 110\n",
      "# of genes inters with Reactom 111\n",
      "# of genes inters with Biocarta 74\n"
     ]
    }
   ],
   "source": [
    "get_output_stats(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(643, 643, 0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genes = []\n",
    "for m in pred_modules:\n",
    "    all_genes.extend(m)\n",
    "    \n",
    "all_genes = set(all_genes)\n",
    "conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "inters = conversion_genes.intersection(all_genes)\n",
    "not_inters = all_genes - inters\n",
    "print(list(not_inters))\n",
    "len(all_genes), len(conversion_genes.intersection(all_genes)), len(not_inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-3...done.\n",
      "Finished.\n",
      "1 input query terms found dup hits:\n",
      "\t[('GOLGA8DP', 3)]\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "res = res[~res['symbol'].isnull()]\n",
    "res = res[~res['entrezgene'].isnull()]\n",
    "res = res[~res['unigene'].isnull()]\n",
    "\n",
    "res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                    else x[0].split('.')[0] == 'Hs' )\n",
    "res = res[res['human'] == True]\n",
    "mapping_kegg = res['entrezgene'].to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "507"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_modules_ids = []\n",
    "all_genes = []\n",
    "count = 0\n",
    "for m in pred_modules:\n",
    "    tmp = []\n",
    "    all_genes.extend(m)\n",
    "    for g in m:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                tmp.append(mapping_kegg[g])\n",
    "\n",
    "    pred_modules_ids.append(tmp)\n",
    "\n",
    "len(pred_modules_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_modules_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0ef3528b761c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mset_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/kegg_Expaner'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/cc_n1771_k3_NCBI_ID.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_modules_ids\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}\\t{}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mset_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pred_modules_ids' is not defined"
     ]
    }
   ],
   "source": [
    "set_id = 0\n",
    "with open('../data/kegg_Expaner'+'/cc_n1771_k3_NCBI_ID.txt', 'w') as f:\n",
    "    for m in pred_modules_ids:\n",
    "        for g in m:\n",
    "            f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "        set_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=4\n",
    "t=1.4\n",
    "# d=2; t=0.92 # these params give # of modules similar to kegg\n",
    "comp_folder = '../out/components/24_06_2019/'\n",
    "comp_file = 'd{}_t{}/cc_n3368_k3.txt'.format(d,t )\n",
    "pred_modules, mapping = predict_modules(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 941 modules \n",
      "There are 1170 unique genes \n",
      "# of genes inters with Kegg 134\n",
      "# of genes inters with Reactom 141\n",
      "# of genes inters with Biocarta 90\n"
     ]
    }
   ],
   "source": [
    "get_output_stats(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1170, 1170, 0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genes = []\n",
    "for m in pred_modules:\n",
    "    all_genes.extend(m)\n",
    "    \n",
    "all_genes = set(all_genes)\n",
    "conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "inters = conversion_genes.intersection(all_genes)\n",
    "not_inters = all_genes - inters\n",
    "\n",
    "print(list(not_inters))\n",
    "len(all_genes), len(conversion_genes.intersection(all_genes)), len(not_inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-bb231c3709be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquerymany\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnot_inters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscopes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'symbol,alias'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'symbol,entrezgene,unigene'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_dataframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspecies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'symbol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'entrezgene'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'unigene'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mg' is not defined"
     ]
    }
   ],
   "source": [
    "res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "res = res[~res['symbol'].isnull()]\n",
    "res = res[~res['entrezgene'].isnull()]\n",
    "res = res[~res['unigene'].isnull()]\n",
    "\n",
    "res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                    else x[0].split('.')[0] == 'Hs' )\n",
    "res = res[res['human'] == True]\n",
    "mapping_reactom = res['entrezgene'].to_dict()\n",
    "mapping_reactom['KIAA1804'] = '84451'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_modules_ids = []\n",
    "all_genes = []\n",
    "count = 0\n",
    "for m in pred_modules:\n",
    "    tmp = []\n",
    "    all_genes.extend(m)\n",
    "    for g in m:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                tmp.append(mapping_reactom[g])\n",
    "\n",
    "    pred_modules_ids.append(tmp)\n",
    "\n",
    "len(pred_modules_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "941"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_id = 0\n",
    "with open('../data/Reactom_Expaner'+'/cc_n3368_k3_NCBI_ID.txt', 'w') as f:\n",
    "    for m in pred_modules_ids:\n",
    "        for g in m:\n",
    "            f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "        set_id += 1\n",
    "set_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biocarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=4\n",
    "t=1.4\n",
    "# d=1; t=1.04 # these params give # of modules similar to kegg\n",
    "comp_folder = '../out/components/24_06_2019/'\n",
    "comp_file = 'd{}_t{}/cc_n1173_k3.txt'.format(d,t )\n",
    "pred_modules, mapping = predict_modules(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 341 modules \n",
      "There are 439 unique genes \n",
      "# of genes inters with Kegg 81\n",
      "# of genes inters with Reactom 79\n",
      "# of genes inters with Biocarta 60\n"
     ]
    }
   ],
   "source": [
    "get_output_stats(comp_folder+comp_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(439, 439, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genes = []\n",
    "for m in pred_modules:\n",
    "    all_genes.extend(m)\n",
    "    \n",
    "all_genes = set(all_genes)\n",
    "conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "inters = conversion_genes.intersection(all_genes)\n",
    "not_inters = all_genes - inters\n",
    "\n",
    "print(list(not_inters))\n",
    "len(all_genes), len(conversion_genes.intersection(all_genes)), len(not_inters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-2...done.\n",
      "Finished.\n",
      "1 input query terms found dup hits:\n",
      "\t[('GUSBP1', 2)]\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "res = res[~res['symbol'].isnull()]\n",
    "res = res[~res['entrezgene'].isnull()]\n",
    "res = res[~res['unigene'].isnull()]\n",
    "\n",
    "res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                    else x[0].split('.')[0] == 'Hs' )\n",
    "res = res[res['human'] == True]\n",
    "mapping_biocarta = res['entrezgene'].to_dict()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_modules_ids = []\n",
    "all_genes = []\n",
    "count = 0\n",
    "for m in pred_modules:\n",
    "    tmp = []\n",
    "    all_genes.extend(m)\n",
    "    for g in m:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                tmp.append(mapping_biocarta[g])\n",
    "\n",
    "    pred_modules_ids.append(tmp)\n",
    "\n",
    "len(pred_modules_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "341"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_id = 0\n",
    "with open('../data/Biocarta_Expaner'+'/cc_n1173_k3_NCBI_ID.txt'.format(d,t ), 'w') as f:\n",
    "    for m in pred_modules_ids:\n",
    "        for g in m:\n",
    "            f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "        set_id += 1\n",
    "set_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing modules for MexCoGrowth on BRCA data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biothings_client import get_client\n",
    "mg = get_client('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-2...done.\n",
      "Finished.\n",
      "2 input query terms found dup hits:\n",
      "\t[('GOLGA8DP', 3), ('IGHA1', 3)]\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "querying 1-2...done.\n",
      "Finished.\n",
      "2 input query terms found dup hits:\n",
      "\t[('GOLGA8DP', 3), ('IGHA1', 3)]\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n",
      "querying 1-1...done.\n",
      "Finished.\n",
      "1 input query terms found dup hits:\n",
      "\t[('IGHA1', 3)]\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "comp_folder = '../out/components/BRCA/mexcogrowth'\n",
    "files = ['cc_n720_k3.txt', 'cc_n957_k3.txt', 'cc_n418_k3.txt']\n",
    "names = ['kegg', 'Reactom', 'Biocarta']\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    \n",
    "    pred_modules, mapping = predict_modules(comp_folder+file)\n",
    "#     print(f'{name}')\n",
    "#     get_output_stats_BRCA(comp_folder+file)\n",
    "#     print(sum([len(s) for s in pred_modules]))\n",
    "#     print('\\n')\n",
    "#     continue \n",
    "    all_genes = []\n",
    "    for m in pred_modules:\n",
    "        all_genes.extend(m)\n",
    "\n",
    "    all_genes = set(all_genes)\n",
    "    conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "    inters = conversion_genes.intersection(all_genes)\n",
    "    not_inters = all_genes - inters\n",
    "    \n",
    "    if len(not_inters) >0: \n",
    "\n",
    "        res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "        res = res[~res['symbol'].isnull()]\n",
    "        res = res[~res['entrezgene'].isnull()]\n",
    "        res = res[~res['unigene'].isnull()]\n",
    "\n",
    "        res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                            else x[0].split('.')[0] == 'Hs' )\n",
    "        res = res[res['human'] == True]\n",
    "        mapping_additional = res['entrezgene'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    pred_modules_ids = []\n",
    "    all_genes = []\n",
    "    count = 0\n",
    "    for m in pred_modules:\n",
    "        tmp = []\n",
    "        all_genes.extend(m)\n",
    "        for g in m:\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "            except:\n",
    "                count += 1\n",
    "                try:\n",
    "                    tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "                except:\n",
    "                    tmp.append(mapping_additional[g])\n",
    "\n",
    "        pred_modules_ids.append(tmp)\n",
    "\n",
    "\n",
    "    set_id = 0\n",
    "    base_name = file.split('/')[-1].split('.')[0]\n",
    "    mkdir(f'../data/{name}_Expaner/BRCA/')\n",
    "    with open(f'../data/{name}_Expaner/BRCA/{base_name}_NCBI_ID.txt', 'w') as f:\n",
    "        for m in pred_modules_ids:\n",
    "            for g in m:\n",
    "                f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "            set_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing modules for other methods (ClusterOne, Hotnet2, and Memcover )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kegg\n",
      "There are 40 modules \n",
      "There are 1770 unique genes \n",
      "# of genes inters with Kegg 136\n",
      "# of genes inters with Reactom 153\n",
      "# of genes inters with Biocarta 86\n",
      "\n",
      "\n",
      "Reactom\n",
      "There are 13 modules \n",
      "There are 3368 unique genes \n",
      "# of genes inters with Kegg 192\n",
      "# of genes inters with Reactom 214\n",
      "# of genes inters with Biocarta 118\n",
      "\n",
      "\n",
      "Biocarta\n",
      "There are 57 modules \n",
      "There are 1173 unique genes \n",
      "# of genes inters with Kegg 104\n",
      "# of genes inters with Reactom 119\n",
      "# of genes inters with Biocarta 67\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Hotnet2\n",
    "comp_folder = '../out/components/hotnet2_intact/intact_threshold_35/'\n",
    "files = ['cc_n1771_k3.txt', 'cc_n3368_k3.txt', 'cc_n1173_k3.txt']\n",
    "names = ['kegg', 'Reactom', 'Biocarta']\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    \n",
    "    pred_modules, mapping = predict_modules(comp_folder+file)\n",
    "#     print(f'{name}')\n",
    "#     get_output_stats(comp_folder+file)\n",
    "#     print('\\n')\n",
    "#     continue \n",
    "    all_genes = []\n",
    "    for m in pred_modules:\n",
    "        all_genes.extend(m)\n",
    "\n",
    "    all_genes = set(all_genes)\n",
    "    conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "    inters = conversion_genes.intersection(all_genes)\n",
    "    not_inters = all_genes - inters\n",
    "    \n",
    "    if len(not_inters) >0: \n",
    "\n",
    "        res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "        res = res[~res['symbol'].isnull()]\n",
    "        res = res[~res['entrezgene'].isnull()]\n",
    "        res = res[~res['unigene'].isnull()]\n",
    "\n",
    "        res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                            else x[0].split('.')[0] == 'Hs' )\n",
    "        res = res[res['human'] == True]\n",
    "        mapping_additional = res['entrezgene'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    pred_modules_ids = []\n",
    "    all_genes = []\n",
    "    count = 0\n",
    "    for m in pred_modules:\n",
    "        tmp = []\n",
    "        all_genes.extend(m)\n",
    "        for g in m:\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "            except:\n",
    "                count += 1\n",
    "                try:\n",
    "                    tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "                except:\n",
    "                    tmp.append(mapping_additional[g])\n",
    "\n",
    "        pred_modules_ids.append(tmp)\n",
    "\n",
    "\n",
    "    set_id = 0\n",
    "    base_name = file.split('/')[-1].split('.')[0]\n",
    "    mkdir(f'../data/{name}_Expaner/hotnet2/')\n",
    "    with open(f'../data/{name}_Expaner/hotnet2/{base_name}_NCBI_ID.txt', 'w') as f:\n",
    "        for m in pred_modules_ids:\n",
    "            for g in m:\n",
    "                f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "            set_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kegg\n",
      "There are 118 modules \n",
      "There are 1291 unique genes \n",
      "# of genes inters with Kegg 105\n",
      "# of genes inters with Reactom 102\n",
      "# of genes inters with Biocarta 71\n",
      "\n",
      "\n",
      "Reactom\n",
      "There are 261 modules \n",
      "There are 2212 unique genes \n",
      "# of genes inters with Kegg 145\n",
      "# of genes inters with Reactom 145\n",
      "# of genes inters with Biocarta 96\n",
      "\n",
      "\n",
      "Biocarta\n",
      "There are 73 modules \n",
      "There are 893 unique genes \n",
      "# of genes inters with Kegg 79\n",
      "# of genes inters with Reactom 77\n",
      "# of genes inters with Biocarta 62\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## ClusterOne\n",
    "comp_folder = '../out/components/25_06_2019/orginal_clusterone/'\n",
    "files = ['cc_n1771_k3.txt', 'cc_n3368_k3.txt', 'cc_n1173_k3.txt']\n",
    "names = ['kegg', 'Reactom', 'Biocarta']\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    \n",
    "    pred_modules, mapping = predict_modules(comp_folder+file)\n",
    "#     print(f'{name}')\n",
    "#     get_output_stats(comp_folder+file)\n",
    "#     print('\\n')\n",
    "#     continue\n",
    "    all_genes = []\n",
    "    for m in pred_modules:\n",
    "        all_genes.extend(m)\n",
    "\n",
    "    all_genes = set(all_genes)\n",
    "    conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "    inters = conversion_genes.intersection(all_genes)\n",
    "    not_inters = all_genes - inters\n",
    "    \n",
    "    if len(not_inters) >0: \n",
    "\n",
    "        res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "        res = res[~res['symbol'].isnull()]\n",
    "        res = res[~res['entrezgene'].isnull()]\n",
    "        res = res[~res['unigene'].isnull()]\n",
    "\n",
    "        res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                            else x[0].split('.')[0] == 'Hs' )\n",
    "        res = res[res['human'] == True]\n",
    "        mapping_additional = res['entrezgene'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    pred_modules_ids = []\n",
    "    all_genes = []\n",
    "    count = 0\n",
    "    for m in pred_modules:\n",
    "        tmp = []\n",
    "        all_genes.extend(m)\n",
    "        for g in m:\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "            except:\n",
    "                count += 1\n",
    "                try:\n",
    "                    tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "                except:\n",
    "                    tmp.append(mapping_additional[g])\n",
    "\n",
    "        pred_modules_ids.append(tmp)\n",
    "\n",
    "\n",
    "    set_id = 0\n",
    "    base_name = file.split('/')[-1].split('.')[0]\n",
    "    mkdir(f'../data/{name}_Expaner/ClusterOne/')\n",
    "    with open(f'../data/{name}_Expaner/ClusterOne/{base_name}_NCBI_ID.txt', 'w') as f:\n",
    "        for m in pred_modules_ids:\n",
    "            for g in m:\n",
    "                f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "            set_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kegg\n",
      "There are 395 modules \n",
      "There are 1386 unique genes \n",
      "# of genes inters with Kegg 155\n",
      "# of genes inters with Reactom 165\n",
      "# of genes inters with Biocarta 106\n",
      "\n",
      "\n",
      "Reactom\n",
      "There are 727 modules \n",
      "There are 2649 unique genes \n",
      "# of genes inters with Kegg 203\n",
      "# of genes inters with Reactom 216\n",
      "# of genes inters with Biocarta 127\n",
      "\n",
      "\n",
      "Biocarta\n",
      "There are 262 modules \n",
      "There are 921 unique genes \n",
      "# of genes inters with Kegg 133\n",
      "# of genes inters with Reactom 139\n",
      "# of genes inters with Biocarta 90\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Memcover\n",
    "comp_folder = '../out/components/memcover_results/'\n",
    "files = ['cc_n1771_k3.txt', 'cc_n3368_k3.txt', 'cc_n1173_k3.txt']\n",
    "names = ['kegg', 'Reactom', 'Biocarta']\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    \n",
    "    pred_modules, mapping = predict_modules(comp_folder+file)\n",
    "#     print(f'{name}')\n",
    "#     get_output_stats(comp_folder+file)\n",
    "#     print('\\n')\n",
    "#     continue\n",
    "    all_genes = []\n",
    "    for m in pred_modules:\n",
    "        all_genes.extend(m)\n",
    "\n",
    "    all_genes = set(all_genes)\n",
    "    conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "    inters = conversion_genes.intersection(all_genes)\n",
    "    not_inters = all_genes - inters\n",
    "    \n",
    "    if len(not_inters) >0: \n",
    "\n",
    "        res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "        res = res[~res['symbol'].isnull()]\n",
    "        res = res[~res['entrezgene'].isnull()]\n",
    "        res = res[~res['unigene'].isnull()]\n",
    "\n",
    "        res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                            else x[0].split('.')[0] == 'Hs' )\n",
    "        res = res[res['human'] == True]\n",
    "        mapping_additional = res['entrezgene'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    pred_modules_ids = []\n",
    "    all_genes = []\n",
    "    count = 0\n",
    "    for m in pred_modules:\n",
    "        tmp = []\n",
    "        all_genes.extend(m)\n",
    "        for g in m:\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "            except:\n",
    "                count += 1\n",
    "                try:\n",
    "                    tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "                except:\n",
    "                    tmp.append(mapping_additional[g])\n",
    "\n",
    "        pred_modules_ids.append(tmp)\n",
    "\n",
    "\n",
    "    set_id = 0\n",
    "    base_name = file.split('/')[-1].split('.')[0]\n",
    "    mkdir(f'../data/{name}_Expaner/memcover/')\n",
    "    with open(f'../data/{name}_Expaner/memcover/{base_name}_NCBI_ID.txt', 'w') as f:\n",
    "        for m in pred_modules_ids:\n",
    "            for g in m:\n",
    "                f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "            set_id += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kegg\n",
      "There are 216 modules \n",
      "There are 1770 unique genes \n",
      "# of genes inters with Kegg 171\n",
      "# of genes inters with Reactom 186\n",
      "# of genes inters with Biocarta 111\n",
      "\n",
      "\n",
      "Reactom\n",
      "There are 350 modules \n",
      "There are 3368 unique genes \n",
      "# of genes inters with Kegg 226\n",
      "# of genes inters with Reactom 246\n",
      "# of genes inters with Biocarta 143\n",
      "\n",
      "\n",
      "Biocarta\n",
      "There are 141 modules \n",
      "There are 1173 unique genes \n",
      "# of genes inters with Kegg 140\n",
      "# of genes inters with Reactom 149\n",
      "# of genes inters with Biocarta 91\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Mexcowalk\n",
    "comp_folder = '../out/components/mexcowalk_intact/'\n",
    "files = ['cc_n1771_k3.txt', 'cc_n3368_k3.txt', 'cc_n1173_k3.txt']\n",
    "names = ['kegg', 'Reactom', 'Biocarta']\n",
    "\n",
    "for file, name in zip(files, names):\n",
    "    \n",
    "    pred_modules, mapping = predict_modules(comp_folder+file)\n",
    "#     print(f'{name}')\n",
    "#     get_output_stats(comp_folder+file)\n",
    "#     print('\\n')\n",
    "#     continue\n",
    "    all_genes = []\n",
    "    for m in pred_modules:\n",
    "        all_genes.extend(m)\n",
    "\n",
    "    all_genes = set(all_genes)\n",
    "    conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())\n",
    "    inters = conversion_genes.intersection(all_genes)\n",
    "    not_inters = all_genes - inters\n",
    "    \n",
    "    if len(not_inters) >0: \n",
    "\n",
    "        res = mg.querymany(list(not_inters), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n",
    "        res = res[~res['symbol'].isnull()]\n",
    "        res = res[~res['entrezgene'].isnull()]\n",
    "        res = res[~res['unigene'].isnull()]\n",
    "\n",
    "        res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                            else x[0].split('.')[0] == 'Hs' )\n",
    "        res = res[res['human'] == True]\n",
    "        mapping_additional = res['entrezgene'].to_dict()\n",
    "\n",
    "\n",
    "\n",
    "    pred_modules_ids = []\n",
    "    all_genes = []\n",
    "    count = 0\n",
    "    for m in pred_modules:\n",
    "        tmp = []\n",
    "        all_genes.extend(m)\n",
    "        for g in m:\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "            except:\n",
    "                count += 1\n",
    "                try:\n",
    "                    tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "                except:\n",
    "                    tmp.append(mapping_additional[g])\n",
    "\n",
    "        pred_modules_ids.append(tmp)\n",
    "\n",
    "\n",
    "    set_id = 0\n",
    "    base_name = file.split('/')[-1].split('.')[0]\n",
    "    mkdir(f'../data/{name}_Expaner/mexcowalk/')\n",
    "    with open(f'../data/{name}_Expaner/mexcowalk/{base_name}_NCBI_ID.txt', 'w') as f:\n",
    "        for m in pred_modules_ids:\n",
    "            for g in m:\n",
    "                f.write('{}\\t{}\\n'.format(g,set_id))\n",
    "            set_id += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the background genes for Expander\n",
    "    the background genes for our analysis are all the genes in the intAct netwrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "intAct_genes = []\n",
    "with open('../data/intact_index_file_theresholded0_35.txt') as f:\n",
    "    intAct_genes = [s.strip().split('\\t')[-1] for s in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversion_genes = set(conversion_df['symbol'].values).union(other_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8684, 20466, 8555, 11911)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inters_ = set(intAct_genes).intersection(conversion_genes.union(set(other_mapping.keys())))\n",
    "len(intAct_genes),len(conversion_genes),len(inters_),len(conversion_genes - inters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(intAct_genes)) - len(inters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_in_ncbi_ = set(intAct_genes) - inters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biothings_client import get_client\n",
    "mg = get_client('gene')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "querying 1-129...done.\n",
      "Finished.\n",
      "32 input query terms found dup hits:\n",
      "\t[('TCL6', 2), ('ANKRD36BP1', 2), ('IGHG1', 3), ('ANKRD26P1', 2), ('STAG3L1', 4), ('SUMO1P1', 2), ('C\n",
      "4 input query terms found no hit:\n",
      "\t['FLJ38668', 'LOC200261', 'LOC730441', 'LOC729862']\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "res = mg.querymany(list(not_in_ncbi_), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = res[~res['symbol'].isnull()]\n",
    "res = res[~res['entrezgene'].isnull()]\n",
    "res = res[~res['unigene'].isnull()]\n",
    "\n",
    "res['human'] = res['unigene'].apply(lambda x: x.split('.')[0] == 'Hs' if isinstance(x, str)\n",
    "                                    else x[0].split('.')[0] == 'Hs' )\n",
    "res = res[res['human'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(118, 7)\n"
     ]
    }
   ],
   "source": [
    "counts = res.index.value_counts()\n",
    "print(counts.shape)\n",
    "one_map = res[counts == 1]\n",
    "print(one_map.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_1 = one_map['entrezgene'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "mult_map = res[counts >1]\n",
    "mapping_2 = mult_map['entrezgene'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = res['entrezgene'].to_dict()\n",
    "len(mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'LOC200261', 'LOC730441', 'LOC729862', 'FLJ38668', 'IGL@'}\n",
      "querying 1-5...done.\n",
      "Finished.\n",
      "4 input query terms found no hit:\n",
      "\t['LOC200261', 'LOC730441', 'LOC729862', 'FLJ38668']\n",
      "Pass \"returnall=True\" to return complete lists of duplicate or missing query terms.\n"
     ]
    }
   ],
   "source": [
    "not_mapped_yet = not_in_ncbi_ - set(mapping.keys())\n",
    "print(not_mapped_yet)\n",
    "res1 = mg.querymany(list(not_mapped_yet), scopes='symbol,alias', fields='symbol,entrezgene,unigene', as_dataframe=True, species='human')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>_score</th>\n",
       "      <th>entrezgene</th>\n",
       "      <th>notfound</th>\n",
       "      <th>symbol</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LOC200261</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC730441</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LOC729862</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLJ38668</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IGL@</th>\n",
       "      <td>3535</td>\n",
       "      <td>20.045826</td>\n",
       "      <td>3535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IGL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            _id     _score entrezgene notfound symbol\n",
       "query                                                \n",
       "LOC200261   NaN        NaN        NaN     True    NaN\n",
       "LOC730441   NaN        NaN        NaN     True    NaN\n",
       "LOC729862   NaN        NaN        NaN     True    NaN\n",
       "FLJ38668    NaN        NaN        NaN     True    NaN\n",
       "IGL@       3535  20.045826       3535      NaN    IGL"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping['FLJ33360'] = '401172'\n",
    "mapping['KIAA1804'] = '84451'\n",
    "mapping['KIAA0664'] = '100132341'\n",
    "mapping['KIAA1045'] = '23349'\n",
    "\n",
    "mapping['IGL@'] = '3535'\n",
    "mapping['LOC200261'] = '200261'\n",
    "mapping['LOC730441'] = '730441'\n",
    "mapping['LOC729862'] = '729862'\n",
    "mapping['FLJ38668'] = '644903'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "intAct_genes_ID = []\n",
    "for g in intAct_genes:\n",
    "    try:\n",
    "        intAct_genes_ID.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "    except:\n",
    "        try:\n",
    "            intAct_genes_ID.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "        except:\n",
    "            \n",
    "            intAct_genes_ID.append(mapping[g])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kegg_Expaner/intact_background_set_IDs.txt', 'w') as f:\n",
    "    f.write('\\n'.join([str(s) for s in intAct_genes_ID]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process the pathway datasetsfor Expander"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The pathway dataset input format:\n",
    "gene_ID\\tcategory_ID\n",
    "\n",
    "there is a mapping file between the name of a category and its ID in the main folder of Expander named map_title.tab\n",
    "\n",
    "05200 will be used as the category_ID\n",
    "\n",
    "05200\tPathways in cancer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/'\n",
    "kegg_pathways = txt_parser2(data_path+'kegg6.2_02_05_2019.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(kegg_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_pathways_ID = []\n",
    "invalid_genes = []\n",
    "kegg_pathways_genes = []\n",
    "for p in kegg_pathways:\n",
    "    kegg_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    kegg_pathways_ID.append(tmp)\n",
    "\n",
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(kegg_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kegg_Expaner/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/kegg_Expaner/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "reactom_pathways = txt_parser2(data_path+'reactom5.0_02_05_2019.txt')\n",
    "\n",
    "len(reactom_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reactom_pathways_ID = []\n",
    "invalid_genes = []\n",
    "reactom_pathways_genes = []\n",
    "for p in reactom_pathways:\n",
    "    reactom_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    reactom_pathways_ID.append(tmp)\n",
    "\n",
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(reactom_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Reactom_Expaner/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/Reactom_Expaner/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biocarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "149"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "biocarta_pathways = txt_parser2(data_path+'biocarta5.0_02_05_2019.txt')\n",
    "\n",
    "len(biocarta_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biocarta_pathways_ID = []\n",
    "invalid_genes = []\n",
    "biocarta_pathways_genes = []\n",
    "for p in biocarta_pathways:\n",
    "    biocarta_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    biocarta_pathways_ID.append(tmp)\n",
    "\n",
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(biocarta_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Biocarta_Expaner/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/Biocarta_Expaner/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Process the pathways files for BRCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "kegg_pathways = txt_parser2(data_path+'kegg6.2_BRCA.txt')\n",
    "\n",
    "len(kegg_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathways_ID = []\n",
    "invalid_genes = []\n",
    "kegg_pathways_genes = []\n",
    "for p in kegg_pathways:\n",
    "    kegg_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    kegg_pathways_ID.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(kegg_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/kegg_Expaner/BRCA/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/kegg_Expaner/BRCA/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "reactom_pathways = txt_parser2(data_path+'reactom5.0_BRCA.txt')\n",
    "\n",
    "len(reactom_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reactom_pathways_ID = []\n",
    "invalid_genes = []\n",
    "reactom_pathways_genes = []\n",
    "for p in reactom_pathways:\n",
    "    reactom_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    reactom_pathways_ID.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(reactom_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Reactom_Expaner/BRCA/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/Reactom_Expaner/BRCA/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biocarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = '../data/'\n",
    "biocarta_pathways = txt_parser2(data_path+'biocarta5.0_BRCA.txt')\n",
    "\n",
    "len(biocarta_pathways)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "biocarta_pathways_ID = []\n",
    "invalid_genes = []\n",
    "biocarta_pathways_genes = []\n",
    "for p in biocarta_pathways:\n",
    "    biocarta_pathways_genes.extend(p)\n",
    "    tmp = []\n",
    "    for g in p:\n",
    "        try:\n",
    "            tmp.append(conversion_df[conversion_df['symbol']==g]['ID'].values[0])\n",
    "        except:\n",
    "            count += 1\n",
    "            try:\n",
    "                tmp.append(conversion_df[conversion_df['symbol']==other_mapping[g]]['ID'].values[0])\n",
    "            except:\n",
    "                invalid_genes.append(g)\n",
    "            \n",
    "    biocarta_pathways_ID.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_genes = set(invalid_genes)\n",
    "len(invalid_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "genId2cat = {}\n",
    "for i,k in enumerate(biocarta_pathways_ID):\n",
    "    for g in k:\n",
    "        try:\n",
    "            _ = genId2cat[g]\n",
    "            genId2cat[g].append(i)\n",
    "        except:\n",
    "            genId2cat[g] = [i]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/Biocarta_Expaner/BRCA/gene_map.tab', 'w') as f:\n",
    "    for k in genId2cat.keys():\n",
    "        f.write('{}\\t{}\\n'.format(k, ' '.join([str(d) for d in genId2cat[k]])))\n",
    "\n",
    "with open('../data/Biocarta_Expaner/BRCA/title_map.tab', 'w') as f:\n",
    "    for i in range(len(kegg_pathways_ID)):\n",
    "        f.write('{}\\tpathway {}\\n'.format(i,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'WHSC1'}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invalid_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene2cat = {}\n",
    "with open('/Users/mac/Downloads/Expander/organisms/human/kegg/gene_map.tab') as f:\n",
    "    lines = [s.strip() for s in f.readlines()]\n",
    "    for l in lines:\n",
    "        l=l.split('\\t')\n",
    "        if '05200' in l[1].split():\n",
    "            gene2cat[l[0]] = l[1].split()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathways_ = {}\n",
    "for id_ in gene2cat.keys():\n",
    "    for cat in gene2cat[id_]:\n",
    "        try:\n",
    "            _ = pathways_[cat]\n",
    "            pathways_[cat].append(id_)\n",
    "        except:\n",
    "            pathways_[cat] = [id_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_paths = 0\n",
    "for p in pathways_.keys():\n",
    "    if len(pathways_[p]) > 2:\n",
    "        valid_paths += 1\n",
    "valid_paths\n",
    "# len(gene2cat.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClusterOne, mexcogrowth, hotnet2, memcover, mexcowalk\n",
    "# kegg, reactom, biocarta\n",
    "comp_folder = '../out/Expander-pathway Enrichment/mexcogrowth/'\n",
    "comp_file = 'biocarta_enrichment_fdr_allgroups_139_modules.txt'\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Enriched with</th>\n",
       "      <th>#genes</th>\n",
       "      <th>Raw p-value</th>\n",
       "      <th>Corrected p-value</th>\n",
       "      <th>Enrichment factor</th>\n",
       "      <th>Gene list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pathway 89</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>192.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>pathway 81</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.00358</td>\n",
       "      <td>256.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>pathway 79</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.00287</td>\n",
       "      <td>384.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pathway 77</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.00301</td>\n",
       "      <td>341.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>pathway 76</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.00301</td>\n",
       "      <td>341.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Enriched with  #genes  Raw p-value  Corrected p-value  \\\n",
       "0    1    pathway 89       2     0.000045            0.00537   \n",
       "1    1    pathway 81       2     0.000025            0.00358   \n",
       "2    1    pathway 79       2     0.000010            0.00287   \n",
       "3    1    pathway 77       2     0.000014            0.00301   \n",
       "4    1    pathway 76       2     0.000014            0.00301   \n",
       "\n",
       "   Enrichment factor         Gene list  \n",
       "0              192.0  [PIK3CA, PIK3R1]  \n",
       "1              256.0  [PIK3CA, PIK3R1]  \n",
       "2              384.0  [PIK3CA, PIK3R1]  \n",
       "3              341.0  [PIK3CA, PIK3R1]  \n",
       "4              341.0  [PIK3CA, PIK3R1]  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 130/1.25\n",
      "Average Enrichment factor 360.8692\n",
      "Total number of enriched genes 32\n",
      "Number of enriched groups 21\n"
     ]
    }
   ],
   "source": [
    "print('Number of Enriched pathways {}/{:.2f}'.format(len(kegg_res_df),len(kegg_res_df)/104))\n",
    "print('Average Enrichment factor {:.4f}'.format(kegg_res_df['Enrichment factor'].mean()))\n",
    "genes_ = []\n",
    "for gene_list in kegg_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "print(f'Total number of enriched genes {len(genes_)}')\n",
    "print(f'Number of enriched groups {len(kegg_res_df[\"Set\"].value_counts())}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.58653846153847"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9941/104"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### backgound set was set to intact genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=4\n",
    "t=1.28\n",
    "comp_folder = '../out/components/IntAct results/28_05_2019_Kegg/'\n",
    "comp_file = 'd{}_t{}/kegg_enrichment_1.txt'.format(d,t )\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Set</th>\n",
       "      <th>Enriched with</th>\n",
       "      <th>#genes</th>\n",
       "      <th>Raw p-value</th>\n",
       "      <th>Corrected p-value</th>\n",
       "      <th>Enrichment factor</th>\n",
       "      <th>Gene list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>pathway 6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.880000e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>[PIK3CA, PTEN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>86</td>\n",
       "      <td>pathway 6</td>\n",
       "      <td>2</td>\n",
       "      <td>1.880000e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>2300.0</td>\n",
       "      <td>[PIK3CA, PTEN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>442</td>\n",
       "      <td>pathway 8</td>\n",
       "      <td>1</td>\n",
       "      <td>6.510000e-04</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>[POLE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>299</td>\n",
       "      <td>pathway 6</td>\n",
       "      <td>2</td>\n",
       "      <td>6.280000e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>[PIK3CA, PLCG1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>pathway 20</td>\n",
       "      <td>2</td>\n",
       "      <td>6.590000e-07</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>1320.0</td>\n",
       "      <td>[PIK3CA, PIK3R1]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Set Enriched with  #genes   Raw p-value  Corrected p-value  \\\n",
       "0   53     pathway 6       2  1.880000e-07           0.000020   \n",
       "1   86     pathway 6       2  1.880000e-07           0.000020   \n",
       "2  442     pathway 8       1  6.510000e-04           0.006150   \n",
       "3  299     pathway 6       2  6.280000e-07           0.000003   \n",
       "4   14    pathway 20       2  6.590000e-07           0.000049   \n",
       "\n",
       "   Enrichment factor         Gene list  \n",
       "0             2300.0    [PIK3CA, PTEN]  \n",
       "1             2300.0    [PIK3CA, PTEN]  \n",
       "2             1540.0            [POLE]  \n",
       "3             1380.0   [PIK3CA, PLCG1]  \n",
       "4             1320.0  [PIK3CA, PIK3R1]  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 9006\n",
      "Average Enrichment factor 275.04271596712925\n"
     ]
    }
   ],
   "source": [
    "print('Number of Enriched pathways {}'.format(len(kegg_res_df)))\n",
    "print('Average Enrichment factor {}'.format(kegg_res_df['Enrichment factor'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR vs Bonfer.. test corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 9657->92.86\n",
      "Average Enrichment factor 272.5769907838848\n"
     ]
    }
   ],
   "source": [
    "# FDR\n",
    "d=4\n",
    "t=1.28\n",
    "comp_folder = '../out/components/IntAct results/28_05_2019_Kegg/'\n",
    "comp_file = 'd{}_t{}/kegg_enrichment_intact_FDR.txt'.format(d,t )\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}->{:.2f}'.format(len(kegg_res_df),len(kegg_res_df)/104 ))\n",
    "print('Average Enrichment factor {}'.format(kegg_res_df['Enrichment factor'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4650\n",
       "2    4204\n",
       "3     758\n",
       "4      41\n",
       "5       4\n",
       "Name: #genes, dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_res_df['#genes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genes_ = []\n",
    "for gene_list in kegg_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "len(genes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 735->7.07\n",
      "Average Enrichment factor 344.605986394558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bonfe\n",
    "d=4\n",
    "t=1.28\n",
    "comp_folder = '../out/components/IntAct results/28_05_2019_Kegg/'\n",
    "comp_file = 'd{}_t{}/kegg_enrichment_intact_Bonf.txt'.format(d,t )\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}->{:.2f}'.format(len(kegg_res_df),len(kegg_res_df)/104 ))\n",
    "print('Average Enrichment factor {}'.format(kegg_res_df['Enrichment factor'].mean()))\n",
    "\n",
    "genes_ = []\n",
    "for gene_list in kegg_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "len(genes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top N = 5, 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 113\n",
      "Average Enrichment factor 224.19115044247792\n"
     ]
    }
   ],
   "source": [
    "# N=5\n",
    "d=4\n",
    "t=1.28\n",
    "comp_folder = '../out/components/IntAct results/28_05_2019_Kegg/'\n",
    "comp_file = 'd{}_t{}/kegg_enrichment_intact_FDR_5.txt'.format(d,t )\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}'.format(len(kegg_res_df)))\n",
    "print('Average Enrichment factor {}'.format(kegg_res_df['Enrichment factor'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 277\n",
      "Average Enrichment factor 272.48808664259906\n",
      "number of enriched genes is 25\n"
     ]
    }
   ],
   "source": [
    "# N=10\n",
    "d=4\n",
    "t=1.28\n",
    "comp_folder = '../out/components/IntAct results/28_05_2019_Kegg/'\n",
    "comp_file = 'd{}_t{}/kegg_enrichment_intact_FDR_10.txt'.format(d,t )\n",
    "kegg_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}'.format(len(kegg_res_df)))\n",
    "print('Average Enrichment factor {}'.format(kegg_res_df['Enrichment factor'].mean()))\n",
    "genes_ = []\n",
    "for gene_list in kegg_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "print('number of enriched genes is {}'.format(len(genes_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    135\n",
       "2    105\n",
       "3     37\n",
       "Name: #genes, dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_res_df['#genes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Set', 'Enriched with', '#genes', 'Raw p-value', 'Corrected p-value',\n",
       "       'Enrichment factor', 'Gene list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kegg_res_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reactom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 6673->19.80\n",
      "Average Enrichment factor 564.5719\n",
      "number of enriched genes is 38\n"
     ]
    }
   ],
   "source": [
    "comp_folder = '../out/Expander-pathway Enrichment/'\n",
    "comp_file = 'reactom_enrichment_intact_FDR.txt'\n",
    "reactom_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}->{:.2f}'.format(len(reactom_res_df),len(reactom_res_df)/337 ))\n",
    "print('Average Enrichment factor {:.4f}'.format(reactom_res_df['Enrichment factor'].mean()))\n",
    "\n",
    "genes_ = []\n",
    "for gene_list in reactom_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "print('number of enriched genes is {}'.format(len(genes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biocarta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Enriched pathways 4110->12.20\n",
      "Average Enrichment factor 632.3866\n",
      "number of enriched genes is 34\n"
     ]
    }
   ],
   "source": [
    "comp_folder = '../out/Expander-pathway Enrichment/'\n",
    "comp_file = 'biocarta_enrichment_intact_FDR.txt'\n",
    "biocarta_res_df = pd.read_csv(comp_folder+comp_file, sep='\\t')\n",
    "\n",
    "print('Number of Enriched pathways {}->{:.2f}'.format(len(biocarta_res_df),len(biocarta_res_df)/337 ))\n",
    "print('Average Enrichment factor {:.4f}'.format(biocarta_res_df['Enrichment factor'].mean()))\n",
    "\n",
    "genes_ = []\n",
    "for gene_list in biocarta_res_df['Gene list'].values:\n",
    "    genes_.extend(gene_list)\n",
    "genes_ = set(genes_)\n",
    "print('number of enriched genes is {}'.format(len(genes_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
